locals {
  cluster_version = "1.21"
}


# https://learn.hashicorp.com/tutorials/terraform/eks
# ________________________________________________________________________________
# EKS Cluster
# ________________________________________________________________________________
module "eks" {
  source                     = "terraform-aws-modules/eks/aws"
  version                    = "18.13.0"

  cluster_name               = var.cluster_name
  cluster_version            = local.cluster_version
  subnet_ids                 = var.subnet_ids
  vpc_id                     = var.vpc_id

  cluster_addons = {
    coredns = {
      resolve_conflicts = "OVERWRITE"
    }
    kube-proxy = {}
    vpc-cni = {
      resolve_conflicts = "OVERWRITE"
    }
  }

  cluster_endpoint_private_access = true
  cluster_endpoint_public_access  = true

  # Extend cluster security group rules
  cluster_security_group_additional_rules = {
    egress_nodes_ephemeral_ports_tcp = {
      description                = "To node 1025-65535"
      protocol                   = "tcp"
      from_port                  = 1025
      to_port                    = 65535
      type                       = "egress"
      source_node_security_group = true
    }
  }

  # Extend node-to-node security group rules
  node_security_group_additional_rules = {
    ingress_self_all = {
      description = "Node to node all ports/protocols"
      protocol    = "-1"
      from_port   = 0
      to_port     = 0
      type        = "ingress"
      self        = true
    }
    egress_all = {
      description      = "Node all egress"
      protocol         = "-1"
      from_port        = 0
      to_port          = 0
      type             = "egress"
      cidr_blocks      = ["0.0.0.0/0"]
      ipv6_cidr_blocks = ["::/0"]
    }
  }

  eks_managed_node_groups = {
    # Default node group - as provided by AWS EKS
    default_node_group = {
      # By default, the module creates a launch template to ensure tags are propagated to instances, etc.,
      # so we need to disable it to use the default template provided by the AWS EKS managed node group service
      create_launch_template = false
      launch_template_name   = ""

      # Remote access cannot be specified with a launch template
      remote_access = {
        ec2_ssh_key               = var.key_pair_name
        source_security_group_ids = [var.public_sg_id]
      }
    }

    # Complete
    complete = {
      name            = "complete-eks-mng"
      use_name_prefix = true

      subnet_ids      = slice(var.subnet_ids, 0, 2)

      min_size     = 1
      max_size     = 3
      desired_size = 1

      ami_id                     = data.aws_ami.eks_default.image_id
      enable_bootstrap_user_data = true
      bootstrap_extra_args       = "--container-runtime containerd --kubelet-extra-args '--max-pods=20'"

      capacity_type        = "SPOT" #  "ON_DEMAND"
      disk_size            = 10
      instance_types       = ["t3.medium", "t3.xlarge"]

      vpc_security_group_ids  = var.vpc_security_group_ids
      create_iam_role          = true
      iam_role_name            = "eks-managed-node-group-tf"
      iam_role_use_name_prefix = false
      iam_role_description     = "EKS managed node group complete example role"
      iam_role_additional_policies = [
        "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      ]
    }

  }

  tags       = {
    cluster    = "${var.resource_prefix}-EKS"
    Name       = var.cluster_name
    Deployment = var.resource_prefix
  }

  # IAM Roles for Service Accounts (IRSA) is a feature of AWS 
  # which allows you to make use of IAM roles at the pod level 
  # by combining an OpenID Connect (OIDC) identity provider 
  # and Kubernetes service account annotations.
  # enable_irsa                   = true

}




data "aws_ami" "eks_default" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["amazon-eks-node-${local.cluster_version}-v*"]
  }
}




output "cluster_id" {
  description = "EKS cluster ID."
  value       = module.eks.cluster_id
}

output "cluster_endpoint" {
  description = "Endpoint for EKS control plane."
  value       = module.eks.cluster_endpoint
}

output "cluster_security_group_id" {
  description = "Security group ids attached to the cluster control plane."
  value       = module.eks.cluster_security_group_id
}

# output "kubectl_config" {
  # description = "kubectl config as generated by the module."
  # value       = module.eks.kubeconfig
# }

# output "config_map_aws_auth" {
  # description = "A kubernetes configuration to authenticate to this EKS cluster."
  # value       = module.eks.config_map_aws_auth
# }

output "cluster_name" {
  description = "Kubernetes Cluster Name"
  value       = var.cluster_name
}

# output "cluster_oidc_issuer_url" {
  # description = "The URL of the EKS cluster OIDC Issuer"
  # value       = module.eks.cluster_oidc_issuer_url
# }

output "oidc_provider_arn" {
  description = "The ARN of the OIDC Provider"
  value       = module.eks.oidc_provider_arn
}

output "cluster_iam_role_arn" {
  description = "IAM role ARN of the EKS cluster"
  value       = module.eks.cluster_iam_role_arn
}

# output "cluster_iam_role_name" {
  # description = "IAM role NAME of the EKS cluster"
  # value       = module.eks.cluster_iam_role_name
# }

# output "worker_iam_role_name" {
  # description = "IAM role name for EKS worker groups"
  # value       = module.eks.worker_iam_role_name
# }

# output "worker_iam_role_arn" {
  # description = "IAM role ARN for EKS worker groups"
  # value       = module.eks.worker_iam_role_arn
# }
